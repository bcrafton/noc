
should we use NoC simulator or something ? 
> https://github.com/davidepatti/noxim
> garnet / gem5 ? 

our thing is so simple is the thing ...

=======

its not interleaved like this
should be 256 / 16 or 128 / 16 ... not 256 total
and lets group PCM + SRAM

=======

allocate
route 
place

=======

route before place
> decouple convolution/matmul and all operations in our graph
> input/output, remove unnecessary information from data structures.

sram allocation is required
> large networks capacity limited
> small networks bandwidth limited

sram loosely coupled from PCM
> layer 1 = 256b/cycle
> layer N = 32b/cycle

=======

consider NoC bandwidth
> crazier our placement, the more it will be stretched.

SRAM bandwidth should always be <= link bandwidth
> can SRAM bandwidth be split ? 64b to right, 64b to left ? 
> what would be the max grouping size for SRAM then ? 128b = 4 SRAMs ? 

how much bandwidth would be needed to supply 128 PCRAMs ?
> 128 SRAMs = 4096b / cycle
> which would be ridiculous

=======

so how do we proceed
we dont really know how to do SRAM for these designs
and dont think we are going to magically figure it out
so we need to step forward and iterate later

> perform proper allocation for PCM
> perform SRAM allocation based on PCM allocation

=======

malloc_SRAM:

# problem is not optimization
# problem is satisfaction

# if we have tons of SRAM, then no problem.
# if not much SRAM, where it is bottleneck or barely enof:

# challenge will be difference between capacity and bandwidth

# do we have to do that here though ? 
# shouldnt this function just allocate, routing figures the rest out ? 

# what if we are capacity constrained ? 
# its realistic because 
# (1) we have all activations on chip
# (2) we are trying to support all kinds of modes
# layer-by-layer 1b-8b could save you here.
# if not enough capacity -> layer-by-layer

# we have to make an assumption though.
# assume there exists enough SRAM capacity 
# BUT, you might have to parition and share SRAMs with bandwidth and capacity.

=======

SRAM allocation = 
capacity
cycles ... every Nth cycle in a period we can allocate out
> we could also distribute 32b/128b banks
> but then we have to give each one a header or something

so keep both options in mind, but start with cycles.

=======

does malloc_SRAM have to do anything then ? 
> make sure we have enof capacity ? 
> allocate SRAM and capacity anyways ?

=======

how we handle the model depends on 
(1) capacity of SRAM -- can you fit all activations on chip
(2) number of PCMs -- if it makes sense to pipeline

is it either:
pipeline
dont pipeline
?
or is there an inbetween ? 

I think there is something inbeteen.
arrays are used for 4 different layers ... but not all
then we have N/4 pipe stages

figuring out when to do what is important.

=======
















